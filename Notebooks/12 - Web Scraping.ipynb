{
  "cells": [
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "# Web Scraping\n\nHave you ever needed to collect data from websites where the data is not made readily available? If you have, then you probably spent a significant amount of time copying and pasting from the website to a spreadsheet, and trying to carefully collect only the information that you need, while avoiding mistakes based on copying and pasting or typing. If your project required that data be collected from *many* pages, then this likely became a painful and repetitive effort that occupied a substantial amount of time.\n\nFortunately, your knowledge of Python can facilitate the data collection process through libraries designed to automate the collection of data from large numbers of pages. This class, we will focus on how to use a few of these libraries to streamline the collection of information from websites. The best way to understand this process is to do it, so we will be walking through the process while learning about why we scrape data the way that we do."
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Accessing a website through Python\n\nObviously, if we want to scrape a website, we will first want to *access* that website. We can do this with the `requests` library, like we did back in Topic 5 to grab some text for our regex experiments."
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nmyPage = requests.get(\"https://brickset.com/sets/year-2020\")",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "During this lesson, we will be using [brickset.com](https://brickset.com/) as our example. This is a GREAT website for learning to scrape, because all of the information that we will attempt to collect can also be collected via the CSV export tool built into the website! This means that we can very easily compare our results against a CSV of the *correct* results to determine whether or not the results of our scrape match the true output of the website. Even better, the website is about Legos, and Legos are the best!\n\nNow we will focus on exploring the page to see what information we can extract."
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Process the HTML"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from bs4 import BeautifulSoup\n\nparsed = BeautifulSoup(myPage.text)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "The code above imports the `BeautifulSoup` library/function, and prepares our requested URL for scraping. When we feed our website into the parser, we need to make sure to pass the `text` attribute of the requested URL, since this is the place in which the full HTML of the page is stored. If we just pass the `myPage` object, then we will be unable to parse the HTML like we want to. Now, we simply store a parsed website as an object (in this case we call it `parsed`), and we are ready to go."
    },
    {
      "metadata": {
        "state": "normal",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "parsed.title",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "<title>2020  | Brickset: LEGO set guide and database</title>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "`BeautifulSoup`'s parsed pages are structured based on the HTML tags that are encountered within the page. For example, above we requested the `title` tag from the page, and we got back the full tag, as well as all content within that tag. In order to only return the text inside the tag, we can use the following code:"
    },
    {
      "metadata": {
        "trusted": true,
        "state": "normal"
      },
      "cell_type": "code",
      "source": "parsed.title.text",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'2020  | Brickset: LEGO set guide and database'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "For a tag with nothing else embedded inside, this is a great way to extract the text. However, many tags will contain one or more other tags, which add to the formatting of the page. The tag that we will be most interested in for now is the `article` tag, which is wrapped around each individual Lego set that is listed on the website. If we just look for the article tag like we did with the title, then we will only see the first article on the page:"
    },
    {
      "metadata": {
        "trusted": true,
        "state": "normal"
      },
      "cell_type": "code",
      "source": "parsed.article",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<article class=\"set\">\n<a class=\"highslide plain mainimg\" href=\"https://images.brickset.com/sets/large/10270-1.jpg?201912060155\" onclick=\"return hs.expand(this)\"><img onerror=\"this.src='/assets/images/spacer2.png'\" src=\"https://images.brickset.com/sets/small/10270-1.jpg?201912060155\" title=\"10270-1: Bookshop\"/></a>\n<div class=\"highslide-caption\">\n<h1>Bookshop</h1><div class=\"tags floatleft\"><a href=\"/sets/10270-1/Bookshop\">10270-1</a> <a href=\"/sets/theme-Creator-Expert\">Creator Expert</a> <a class=\"subtheme\" href=\"/sets/theme-Creator-Expert/subtheme-Modular-Buildings\">Modular Buildings</a> <a class=\"year\" href=\"/sets/theme-Creator-Expert/year-2020\">2020</a> </div><div class=\"floatright\">©2020 LEGO Group</div>\n<div class=\"pn\">\n<a href=\"#\" onclick=\"return hs.previous(this)\" title=\"Previous (left arrow key)\">« Previous</a>\n<a href=\"#\" onclick=\"return hs.next(this)\" title=\"Next (right arrow key)\">Next »</a>\n</div>\n</div>\n<div class=\"meta\"><h1><a href=\"/sets/10270-1/Bookshop\"><span>10270: </span> Bookshop</a></h1><div class=\"tags\"><a href=\"/sets/10270-1/Bookshop\">10270-1</a> <a href=\"/sets/theme-Creator-Expert\">Creator Expert</a> <a class=\"subtheme\" href=\"/sets/theme-Creator-Expert/subtheme-Modular-Buildings\">Modular Buildings</a> <a class=\"year\" href=\"/sets/theme-Creator-Expert/year-2020\">2020</a> </div><div class=\"tags\"><span id=\"tags29830\"><a href=\"/sets/tag-Baseplate\">Baseplate</a> <a href=\"/sets/tag-Shop\"> Shop</a> <a href=\"/sets/tag-Lamppost\"> Lamppost</a> <a href=\"/sets/tag-Bedroom\"> Bedroom</a> <a href=\"/sets/tag-Fireplace\"> Fireplace</a> <a href=\"/sets/tag-Brick-Built-Tree\"> Brick Built Tree</a> <a href=\"/sets/tag-Modular-Building\"> Modular Building</a> </span></div><div class=\"rating\" title=\"4.5\"><span class=\"full\">✭</span><span class=\"full\">✭</span><span class=\"full\">✭</span><span class=\"full\">✭</span><span class=\"empty\">✩</span> <a href=\"/reviews/set-10270-1\">2 reviews</a></div><div class=\"col\"><dl><dt>Pieces</dt><dd><a class=\"plain\" href=\"/inventories/10270-1\">2504</a></dd><dt>Minifigs</dt><dd><a class=\"plain\" href=\"/minifigs/inset-10270-1\">5</a></dd><dt>RRP</dt><dd>$179.99, 159.99€ | <a class=\"popuplink plain\" href=\"prices?set=10270-1\">More</a></dd><dt>PPP</dt><dd>7.2c, 6.4c</dd><dt>Packaging</dt><dd>Box</dd><dt>Availability</dt><dd>Retail - limited</dd><dt>First sold</dt><dd>USA: Jan 20, UK/EU: Jan 20</dd><dt>Instructions</dt><dd><a class=\"popuplink plain\" href=\"instructions2?set=10270-1&amp;s=1\">Yes</a></dd><dt>Additional images</dt><dd><a class=\"plain\" href=\"/sets/10270-1?more-images\">37</a></dd><dt>Set type</dt><dd>Normal</dd></dl></div><div class=\"col\"><dl></dl><dl class=\"highlight\"></dl></div></div><div class=\"action\"><dl class=\"admin\"><dt class=\"hideingallery\">Our community</dt><dd class=\"hideingallery\"><a class=\"popuplink\" href=\"ownedBy?SetID=29830\">3997 own this set</a>, 5165 want it</dd></dl><dl class=\"buylinks\"><dt>Buy this set at</dt><dd><ul><li>\n<a class=\"lego\" href=\"https://click.linksynergy.com/link?id=oSv/vWYkQIY&amp;offerid=115554.10270&amp;type=15&amp;murl=https%3A%2F%2Fwww.lego.com%2Fen-us%2Fproduct%2Fbookshop-10270\">LEGO</a></li><li>\n<a class=\"amazon\" href=\"https://www.amazon.com/s/?url=search-alias=aps&amp;field-keywords=LEGO%2010270&amp;tag=brickset-20&amp;link_code=wql&amp;camp=212361&amp;creative=380601&amp;_encoding=UTF-8\">Amazon</a>\n</li><li>\n<a class=\"ebay\" href=\"https://rover.ebay.com/rover/1/711-53200-19255-0/1?icep_ff3=9&amp;pub=5574779132&amp;toolid=10001&amp;campid=5336183597&amp;customid=&amp;icep_uq=LEGO+10270&amp;icep_sellerId=&amp;icep_ex_kw=&amp;icep_sortBy=12&amp;icep_catId=&amp;icep_minPrice=&amp;icep_maxPrice=&amp;ipn=psmain&amp;icep_vectorid=229466&amp;kwid=902099&amp;mtid=824&amp;kw=lg\">eBay</a>\n</li><li>\n<a class=\"bricklink\" href='http://alpha.bricklink.com/pages/clone/catalogitem.page?S=10270-1#T=S&amp;O={\"ss\":\"US\"}'>BrickLink</a>\n</li></ul></dd></dl></div></article>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "Wow! There sure is a lot of stuff for us to work through within that tag! It turns out that the article tag contains *everything* related to a particular set, so we will have to work through that information more carefully if we would like to be able to scrape information about each set. \n\nThe first thing that we need to do, though, is collect ALL of the article tags (or all of the sets), so that we can scrape each one and collect the most useful information."
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Explore the Page\n\nOur processed website has some other tools besides being able to reference each tag. One of the most helpful is a method called `find_all`, which will allow us to look in a specific portion of the page (or across the whole page) for *all instances* of a specific tag. Before, we could only see the first instance of the article tag, but this will allow us to find all the articles on a page!\n\nIn order to not end up with a massive text blob for output, let's store the results of our `find_all` method in a list."
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "a = [i for i in parsed.find_all('article')]",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "To store the article tags in a list, we use a simple list comprehension, so that each separate article tag is a new entry in the list called `a`. One of the really cool things about `BeautifulSoup` is that each object is treated just like the full parsed webpage: we can use tags as attributes to walk through each of our new objects in the list.\n\nLet's try finding a `ul` tag inside of the first article:"
    },
    {
      "metadata": {
        "trusted": true,
        "state": "normal"
      },
      "cell_type": "code",
      "source": "a[0].ul",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "<ul><li>\n<a class=\"lego\" href=\"https://click.linksynergy.com/link?id=oSv/vWYkQIY&amp;offerid=115554.10270&amp;type=15&amp;murl=https%3A%2F%2Fwww.lego.com%2Fen-us%2Fproduct%2Fbookshop-10270\">LEGO</a></li><li>\n<a class=\"amazon\" href=\"https://www.amazon.com/s/?url=search-alias=aps&amp;field-keywords=LEGO%2010270&amp;tag=brickset-20&amp;link_code=wql&amp;camp=212361&amp;creative=380601&amp;_encoding=UTF-8\">Amazon</a>\n</li><li>\n<a class=\"ebay\" href=\"https://rover.ebay.com/rover/1/711-53200-19255-0/1?icep_ff3=9&amp;pub=5574779132&amp;toolid=10001&amp;campid=5336183597&amp;customid=&amp;icep_uq=LEGO+10270&amp;icep_sellerId=&amp;icep_ex_kw=&amp;icep_sortBy=12&amp;icep_catId=&amp;icep_minPrice=&amp;icep_maxPrice=&amp;ipn=psmain&amp;icep_vectorid=229466&amp;kwid=902099&amp;mtid=824&amp;kw=lg\">eBay</a>\n</li><li>\n<a class=\"bricklink\" href='http://alpha.bricklink.com/pages/clone/catalogitem.page?S=10270-1#T=S&amp;O={\"ss\":\"US\"}'>BrickLink</a>\n</li></ul>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "Awesome! We can walk through that list if we would like, as well!\n\nNext, let's see how many articles are stored on each page of search results:"
    },
    {
      "metadata": {
        "state": "normal",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "parsed.find(\"ul\", class_=\"pagelength\").span.text",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'25'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "It looks like each results page has 25 or fewer results. How did we know to look for a `ul` tag that had the class `pagelength`? We opened a page of results up, and we used the developer \"Inspect\" tool built into our browser to help us find the part of the page that tells us how many results will be shown on each page. As we prepare to scrape a page, we will spend a lot of time going back and forth between the website as we see it, and the code that we are designing to scrape that website.\n\nAs we look through our list of articles, though, we will want to start extracting information that will help us learn about each Lego set. Let's try our hand at finding the name of the sets, and the price of the sets in Euros. Fortunately, the title of each set will be very easy to find. If we inspect the title of the first result (using the link that we started with at the top of the notebook), we can see that the name of the set is stored within the article tag using an `h1` tag. Let's request that from our list:"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "a[0].h1.text",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "'Bookshop'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "Perfect! We get back the text title for our first search result! We can also return the title of each set on the page:"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "state": "normal"
      },
      "cell_type": "code",
      "source": "[i.h1.text for i in a]",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "['Bookshop',\n 'Fiat 500',\n 'Old Trafford - Manchester United',\n 'Haunted House',\n '{?}',\n '{?}',\n '{?}',\n 'Crocodile Locomotive',\n 'Heart Box',\n 'Brick Box',\n 'Deluxe Brick Box',\n 'Alphabet Truck',\n 'Fire Truck',\n 'Tow Truck',\n 'Batcave',\n \"Elsa and Olaf's Tea Party\",\n 'Super Heroes Lab',\n \"Ariel's Undersea Castle\",\n \"Lightning McQueen's Race Day\",\n 'Playroom',\n 'Bedroom',\n 'Pizza Stand',\n 'Bakery',\n 'Modular Playhouse',\n 'Bulldozer']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "That was the easy part. Now that we have the set names, we need to find their prices. We will start by finding their prices on the website itself. We can see that the prices are listed in both dollars and Euros, and that they are always shown next to text that says \"RRP\". This stands for Recommended Retail Price, and is the number we want to collect.\n\nOur first step in extracting the price is to note that, because the price changes from set to set, we are going to have to find some other consistent marker from which we can reference the price. That marker is the text \"RRP\". We need to describe a way to always reach that text, no matter which set we are focused on. If we inspect the page, we will see that \"RRP\" is contained in a `dt` tag. There are several of these tags, each containing different information about the set, so we will need to make sure that we get the right one.\n\nUsing the `.find` method, we can tell `BeautifulSoup` to look for a tag of specific kind (in this case, `dt`) with some attribute (in this case, text that is equal to \"RRP\")."
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "a[0].find('dt', text=\"RRP\")",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<dt>RRP</dt>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "Got it! This isn't so bad if we just move slowly. Next up, we need to make our way from the \"RRP\" tag to the tag containing the price. It turns out that `dt` tags are part of a table, and each one will correspond to a `dd` tag. These tags within a table are considered **siblings**, meaning that they exist embedded within the same tag as one another. \n\nSince the `dd` tag containing the price ALWAYS immediately follows the `dt` containing \"RRP\", we can use the `.find_next_sibling()` method to move from the `dt` tag to the `dd` tag! The price is contained as the text of the `dd` tag, so let's go ahead and grab that text, now."
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "a[0].find('dt', text=\"RRP\").find_next_sibling().text",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "'$179.99, 159.99€ | More'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "Almost there.... Unfortunately, the text contains more stuff than just the price in Euros. It turns out that the website just has a blob of text that contains prices, possibly in dollars, possibly in Euros, and possibly both, with some extra text at the end. Since price isn't a consistent number of digits, we need a way to recognize patterns in text and extract only the part that we want.\n\nRegular expression comes to the rescue!"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\n\nre.search(r'(\\d+.\\d+)(\\u20AC)', a[0].find('dt', text=\"RRP\").find_next_sibling().text, re.UNICODE).groups()[0]",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "'159.99'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "`r'(\\d+.\\d+)(\\u20AC)'` is a regular expression that looks for one or more numbers before a period, a period, and one or more numbers after the period followed by the Euro symbol (`\\u20AC` is the code that represents the Euro symbol). We simply provide the string to the `re.search` function, along with our regular expression and an extra argument (`re.UNICODE`) that allows us to find less common characters like the Euro symbol.\n\nWhen we get back the results from this search, we only need the first group (or value in parentheses), which omits the Euro symbol. This will return only the number value representing the price of the set. It's a string, but we can easily convert it to a number using the `float()` function.\n\nNow that we know how to find each of the two values that we care about, it is time to start formalizing our code with a `for` loop to grab the same pieces of information from each set. We can use our loop to walk through each `article` tag and extract the relevant information."
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = []\n\nfor i in a:\n    row = []\n    row.append(i.h1.text)\n    try:\n        row.append(re.search(r'(\\d+.\\d+)(\\u20AC)', i.find('dt', text=\"RRP\").find_next_sibling().text, re.UNICODE).groups()[0])\n    except:\n        row.append('')\n    data.append(row)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "We created an empty list called `data`, and our `for` loop was used to add rows to that list. Each row consists of a list of two items: set name and set price. Once we have created the list representing that row, we simply append it to the `data` list and move on to the next set.\n\nThe next step (below) is to create a Data Frame based on our list called `data`, and to name our columns. This provides easy structure and functionality to our data:"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ndata = pd.DataFrame(data, columns = ['Set', 'Price_Euro'])\n\ndata",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "                                 Set Price_Euro\n0                           Bookshop     159.99\n1                           Fiat 500      79.99\n2   Old Trafford - Manchester United     269.99\n3                      Haunted House     229.99\n4                                {?}           \n5                                {?}           \n6                                {?}           \n7               Crocodile Locomotive      99.99\n8                          Heart Box      19.99\n9                          Brick Box      29.99\n10                  Deluxe Brick Box      49.99\n11                    Alphabet Truck      29.99\n12                        Fire Truck       4.99\n13                         Tow Truck       4.99\n14                           Batcave      34.99\n15         Elsa and Olaf's Tea Party      19.99\n16                  Super Heroes Lab      29.99\n17           Ariel's Undersea Castle      29.99\n18      Lightning McQueen's Race Day      29.99\n19                          Playroom      14.99\n20                           Bedroom      14.99\n21                       Pizza Stand       9.99\n22                            Bakery      39.99\n23                 Modular Playhouse      59.99\n24                         Bulldozer       9.99",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Set</th>\n      <th>Price_Euro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bookshop</td>\n      <td>159.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fiat 500</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Old Trafford - Manchester United</td>\n      <td>269.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Haunted House</td>\n      <td>229.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Crocodile Locomotive</td>\n      <td>99.99</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Heart Box</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Brick Box</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Deluxe Brick Box</td>\n      <td>49.99</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Alphabet Truck</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Fire Truck</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Tow Truck</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Batcave</td>\n      <td>34.99</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Elsa and Olaf's Tea Party</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Super Heroes Lab</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Ariel's Undersea Castle</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Lightning McQueen's Race Day</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Playroom</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Bedroom</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Pizza Stand</td>\n      <td>9.99</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Bakery</td>\n      <td>39.99</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Modular Playhouse</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Bulldozer</td>\n      <td>9.99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Moving On (to the next page)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we have established a patter of code that is able to collect the information we desire, it is time to make sure that we can collect the same information from each page of search results. It is typically insufficient to collect only one page of search results, so we want to be able to follow the links in our search from page to page in order to continue collecting data.\n\nOn the page, we can inspect the button that navigates from one page to the next. We find that the element is an `li` or list item tag, with a class of `next`. Using the `find` method, we can can then extract the `href` parameter from the `a` tag representing the link that takes us to the next page:"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "nextPage = parsed.find('li', class_=\"next\").a['href']\n\nnextPage",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "'https://brickset.com/sets/year-2020/page-2'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This link certainly looks like it will take us to the next page of results! Now, we can consolidate the code that we used above into a single code block, so that we can recycle our code to collect data from another page of search results. Below is the code that we have collected so far, applied to the second page of results."
    },
    {
      "metadata": {
        "scrolled": false,
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "myPage = requests.get(nextPage)\n\nparsed = BeautifulSoup(myPage.text)\na = [i for i in parsed.find_all('article')]\n\nnewData = []\n\nfor i in a:\n    row = []\n    row.append(i.h1.text)\n    try:\n        row.append(re.search(r'(\\d+.\\d+)(\\u20AC)', i.find('dt', text=\"RRP\").find_next_sibling().text, re.UNICODE).groups()[0])\n    except:\n        row.append('')\n    newData.append(row)\n\nnewData = pd.DataFrame(newData, columns = ['Set', 'Price_Euro'])\n\nnewData",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "                            Set Price_Euro\n0     Truck & Tracked Excavator      19.99\n1      Wrecking Ball Demolition      59.99\n2    Tower Crane & Construction     119.99\n3              Creative Animals      59.99\n4          Creative Blue Bricks       4.99\n5         Creative Green Bricks       4.99\n6             Bricks and Houses      19.99\n7             Bricks and Lights      29.99\n8               White Baseplate       7.99\n9            Bricks and Animals      59.99\n10         Bricks Bricks Plates      69.99\n11                        Tokyo      59.99\n12                        Dubai      59.99\n13              The White House      99.99\n14    BigFig Creeper and Ocelot      14.99\n15  BigFig Pig with Baby Zombie      14.99\n16            The Panda Nursery      19.99\n17         The Pillager Outpost      29.99\n18             The Illager Raid      69.99\n19         The Crafting Box 3.0      79.99\n20          The Taiga Adventure       9.99\n21          The Redstone Battle      54.99\n22  International Space Station      69.99\n23     Pirates of Barracuda Bay     199.99\n24                          {?}           ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Set</th>\n      <th>Price_Euro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Truck &amp; Tracked Excavator</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wrecking Ball Demolition</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tower Crane &amp; Construction</td>\n      <td>119.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Creative Animals</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Creative Blue Bricks</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Creative Green Bricks</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Bricks and Houses</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Bricks and Lights</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>White Baseplate</td>\n      <td>7.99</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Bricks and Animals</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Bricks Bricks Plates</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Tokyo</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Dubai</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The White House</td>\n      <td>99.99</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>BigFig Creeper and Ocelot</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>BigFig Pig with Baby Zombie</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>The Panda Nursery</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>The Pillager Outpost</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>The Illager Raid</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>The Crafting Box 3.0</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>The Taiga Adventure</td>\n      <td>9.99</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>The Redstone Battle</td>\n      <td>54.99</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>International Space Station</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Pirates of Barracuda Bay</td>\n      <td>199.99</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Additionally, we can concatenate our Data Frames so that we have a single Data Frame containing all of the results from our scrape. After we concatenate our data, it is good practice to reset the index using the `.reset_index()` method. This will overwrite the index of the Data Frame so that it does not have any repeat values. Be sure to include the argument `drop=True`, so that the old index isn't added back into your Data Frame."
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = pd.concat([data, newData], axis=0).reset_index(drop=True)\n\ndata",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "                                 Set Price_Euro\n0                           Bookshop     159.99\n1                           Fiat 500      79.99\n2   Old Trafford - Manchester United     269.99\n3                      Haunted House     229.99\n4                                {?}           \n5                                {?}           \n6                                {?}           \n7               Crocodile Locomotive      99.99\n8                          Heart Box      19.99\n9                          Brick Box      29.99\n10                  Deluxe Brick Box      49.99\n11                    Alphabet Truck      29.99\n12                        Fire Truck       4.99\n13                         Tow Truck       4.99\n14                           Batcave      34.99\n15         Elsa and Olaf's Tea Party      19.99\n16                  Super Heroes Lab      29.99\n17           Ariel's Undersea Castle      29.99\n18      Lightning McQueen's Race Day      29.99\n19                          Playroom      14.99\n20                           Bedroom      14.99\n21                       Pizza Stand       9.99\n22                            Bakery      39.99\n23                 Modular Playhouse      59.99\n24                         Bulldozer       9.99\n25         Truck & Tracked Excavator      19.99\n26          Wrecking Ball Demolition      59.99\n27        Tower Crane & Construction     119.99\n28                  Creative Animals      59.99\n29              Creative Blue Bricks       4.99\n30             Creative Green Bricks       4.99\n31                 Bricks and Houses      19.99\n32                 Bricks and Lights      29.99\n33                   White Baseplate       7.99\n34                Bricks and Animals      59.99\n35              Bricks Bricks Plates      69.99\n36                             Tokyo      59.99\n37                             Dubai      59.99\n38                   The White House      99.99\n39         BigFig Creeper and Ocelot      14.99\n40       BigFig Pig with Baby Zombie      14.99\n41                 The Panda Nursery      19.99\n42              The Pillager Outpost      29.99\n43                  The Illager Raid      69.99\n44              The Crafting Box 3.0      79.99\n45               The Taiga Adventure       9.99\n46               The Redstone Battle      54.99\n47       International Space Station      69.99\n48          Pirates of Barracuda Bay     199.99\n49                               {?}           ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Set</th>\n      <th>Price_Euro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bookshop</td>\n      <td>159.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fiat 500</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Old Trafford - Manchester United</td>\n      <td>269.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Haunted House</td>\n      <td>229.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Crocodile Locomotive</td>\n      <td>99.99</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Heart Box</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Brick Box</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Deluxe Brick Box</td>\n      <td>49.99</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Alphabet Truck</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Fire Truck</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Tow Truck</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Batcave</td>\n      <td>34.99</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Elsa and Olaf's Tea Party</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Super Heroes Lab</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Ariel's Undersea Castle</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Lightning McQueen's Race Day</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Playroom</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Bedroom</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Pizza Stand</td>\n      <td>9.99</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Bakery</td>\n      <td>39.99</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Modular Playhouse</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Bulldozer</td>\n      <td>9.99</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Truck &amp; Tracked Excavator</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Wrecking Ball Demolition</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Tower Crane &amp; Construction</td>\n      <td>119.99</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Creative Animals</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Creative Blue Bricks</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Creative Green Bricks</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Bricks and Houses</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Bricks and Lights</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>White Baseplate</td>\n      <td>7.99</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Bricks and Animals</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Bricks Bricks Plates</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Tokyo</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Dubai</td>\n      <td>59.99</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>The White House</td>\n      <td>99.99</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>BigFig Creeper and Ocelot</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>BigFig Pig with Baby Zombie</td>\n      <td>14.99</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>The Panda Nursery</td>\n      <td>19.99</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>The Pillager Outpost</td>\n      <td>29.99</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>The Illager Raid</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>The Crafting Box 3.0</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>The Taiga Adventure</td>\n      <td>9.99</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>The Redstone Battle</td>\n      <td>54.99</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>International Space Station</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Pirates of Barracuda Bay</td>\n      <td>199.99</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>{?}</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Functional Scraping Code\n\nWe talked about functions earlier in the term as an excellent way to make our code more reusable, and to eliminate the need to copy and paste code with the risk of creating more typos and places for code to be updated. Now that we know how to scrape useful information from a website, let's create a function to do the work for us, so that we don't have to copy and paste the code for each subsequent page of search results.\n\nIn order to make our code into a function, we will have to create a function that takes a starting URL (the URL for our search results), and returns a Data Frame after reading through each page of the search results. We will have to perform some abstraction to make our code work on each page, but the differences are pretty minor:\n\n- Use `requests.get()` on the URL passed to the function\n- Check whether or not a \"next\" page exists\n    - If there IS a next page, we need to call the function on *that* page, then merge the results\n    - If there is NOT a next page, we return the existing data as a Data Frame.\n    \nTake some time to examine the code below and how each of these changes is made:"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport pandas as pd\nimport re\n\n# A function to collect lego sets from search results on brickset.com\ndef collectLegoSets(startURL):\n    # Retrieve starting URL\n    myPage = requests.get(startURL)\n\n    # Parse the website with Beautiful Soup\n    parsed = BeautifulSoup(myPage.text)\n    \n    # Grab all sets from the page\n    a = [i for i in parsed.find_all('article')]\n\n    # Create and empty data set\n    newData = []\n\n    # Iterate over all sets on the page\n    for i in a:\n        row = []\n        # Add the set name to the row of data\n        row.append(i.h1.text)\n        try:\n            # Extract price and translate to a floating point number from string, append to row IF PRICE EXISTS\n            row.append(float(re.search(r'(\\d+.\\d+)(\\u20AC)', i.find('dt', text=\"RRP\").find_next_sibling().text, re.UNICODE).groups()[0]))\n        except:\n            # Missing value for sets with no price, append to row IF NO PRICE EXISTS\n            row.append(np.nan)\n        \n        # Add the row of data to the dataset\n        newData.append(row)\n\n    newData = pd.DataFrame(newData, columns = ['Set', 'Price_Euro'])\n    \n    # Check if there are more results on the \"next\" page\n    try:\n        nextPage = parsed.find('li', class_=\"next\").a['href']\n    except:\n        nextPage = None\n    \n    # If there is another page of results, grab it and combine\n    if nextPage:\n        return pd.concat([newData, collectLegoSets(nextPage)], axis=0)\n    # Otherwise return the current data\n    else:\n        return newData",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "One important note is that we use several `try`-`except` blocks. These code blocks permit us to write code that *might* result in an error. This is the code that is indented beneath the `try` keyword. Then, we write code that should be executed whenever an error *does* occur under the `except` keyword. In this way, we prevent errors from breaking our function, and we can better control the data that is recorded in our Data Frame. Let's run the code now:"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "lego2020 = collectLegoSets(\"https://brickset.com/sets/year-2020\")\n\nlego2020",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "                                     Set  Price_Euro\n0                               Bookshop      159.99\n1                               Fiat 500       79.99\n2       Old Trafford - Manchester United      269.99\n3                          Haunted House      229.99\n4                                    {?}         NaN\n..                                   ...         ...\n11                  Building LEGO Trains         NaN\n12     Porsche 911: Legends Made of LEGO         NaN\n13  Iconic Objects Made From LEGO Bricks         NaN\n14                             Newsstand         NaN\n15                      Valentine's Bear         NaN\n\n[641 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Set</th>\n      <th>Price_Euro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bookshop</td>\n      <td>159.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fiat 500</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Old Trafford - Manchester United</td>\n      <td>269.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Haunted House</td>\n      <td>229.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{?}</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Building LEGO Trains</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Porsche 911: Legends Made of LEGO</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Iconic Objects Made From LEGO Bricks</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Newsstand</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Valentine's Bear</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>641 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There you have it! A single, easy-to-read function that will collect data on all Lego sets from the year 2020 into a Data Frame for us to analyze. We can even use this Data Frame to streamline calculations:"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "lego2020['Price_Euro'].mean()",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "40.605598885793874"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the data we have collected, the mean price (in Euros) of 2020 Lego sets is 40.61€.\n\nNow, it's your turn to collect data!"
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "**Solve it**:\n\nUpdate the code used in this lesson to extract the following information regarding Lego sets from the year 2019:\n- Name of the set\n- Price of the set (in Euros)\n- Number of pieces\n- Number of minifigs\n\nYou should collect this information for ALL lego sets from 2019 (there are 820). Store your results in a Data Frame called `lego2019`. The columns should be labeled `Set`, `Price_Euro`, `Pieces`, `Minifigs`, respectively. The Data Frame should have the first page of results at the top, and the last page of results at the bottom (this order will enable comparison of your results with mine). You will receive points for the following:\n\n- `lego2019` contains 820 entries [1 point]\n- Columns are labeled `Set`, `Price_Euro`, `Pieces`, `Minifigs`, respectively [1 point]\n- Column `Set` contains the correct names for each set [1 point]\n- Column `Price_Euro` contains the correct price in Euros for each set (missing prices should be replaced with `np.nan`) [1 point]\n- Column `Pieces` contains the correct number of pieces (replaced with `np.nan` where missing) [1 point]\n\n\n*WARNING: This submission will be slow to grade, since it will take a while for your code to scrape the website and process the data! Be patient. The grading algorithm will give you 180 seconds before it stops grading.*\n\nPlease put ALL NECESSARY CODE into the cell below:\n\n"
    },
    {
      "metadata": {
        "state": "graded",
        "id": "aged_nott",
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport pandas as pd\nimport re\n\n# A function to collect lego sets from search results on brickset.com\ndef collectLegoSets(startURL):\n    # Retrieve starting URL\n    myPage = requests.get(startURL)\n\n    # Parse the website with Beautiful Soup\n    parsed = BeautifulSoup(myPage.text)\n    \n    # Grab all sets from the page\n    a = [i for i in parsed.find_all('article')]\n\n    # Create and empty data set\n    newData = []\n\n    # Iterate over all sets on the page\n    for i in a:\n        row = []\n        # Add the set name to the row of data\n        row.append(i.h1.text)\n        try:\n            # Extract price and translate to a floating point number from string, append to row IF PRICE EXISTS\n            row.append(float(re.search(r'(\\d+.\\d+)(\\u20AC)', i.find('dt', text=\"RRP\").find_next_sibling().text, re.UNICODE).groups()[0]))\n        except:\n            # Missing value for sets with no price, append to row IF NO PRICE EXISTS\n            row.append(np.nan)\n            \n        try:\n            row.append(int(i.find('dt', text=\"Pieces\").find_next_sibling().text))\n        except:\n            # Missing value for sets with no pieces info\n            row.append(np.nan)\n            \n        try:\n            row.append(int(i.find('dt', text=\"Minifigs\").find_next_sibling().text))        \n        except:\n            # Missing value for sets with no minifigs info\n            row.append(np.nan)\n        \n        # Add the row of data to the dataset\n        newData.append(row)\n\n    newData = pd.DataFrame(newData, columns = ['Set', 'Price_Euro', 'Pieces', 'Minifigs'])\n    \n    # Check if there are more results on the \"next\" page\n    try:\n        nextPage = parsed.find('li', class_=\"next\").a['href']\n    except:\n        nextPage = None\n    \n    # If there is another page of results, grab it and combine\n    if nextPage:\n        return pd.concat([newData, collectLegoSets(nextPage)], axis=0).reset_index(drop=True)\n    # Otherwise return the current data\n    else:\n        return newData\n    \nlego2019 = collectLegoSets(\"https://brickset.com/sets/year-2019\")",
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "mimir": {
      "project_id": "68d2efa0-cc4f-46ee-89cf-64ceba246808",
      "last_submission_id": "",
      "data": {}
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}